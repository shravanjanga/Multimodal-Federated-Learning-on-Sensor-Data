**Motivation:**
According to the papers, Federated Learning(FL) is a type of learning that allows for users to train on models without compromising the raw data itself. Multimodal sensor data is data this collected through various means such as images, audio, etc. in an Internet of things enviromet. This project is a way to implement multimodal learning through existing datasets.
  
**Design Goals:**
- Benchmarking: Replicate paper results using provided datasets.
- Accuracy Analysis: Evaluate per-class accuracy and address skewed data.
- Data Distribution: Study the impact of imbalanced data

**Deliverables:**
- Reproduced experimental results.
- Per-class accuracy analysis.
- Insights into data distribution's effect.
- Evaluation on balanced datasets.

**System Blocks:**
- FL from given code
- Dataset
- Preprocess data
- Model training
- Data Analysis

**Hardware/Software Requirements:**
- Python Environment.
- Laptop with CUDA-enabled GPU.

**Team Members:** Shravan Janga - Will be leading all roles including setup, software, networking, writing, research, algorithm design

**Timeline:**
- Week 1(10/1/23 - 10/7/23): Understand FL, Set up Environment.
- Week 2-3(10/8/23 - 10/22/23): Replicate Experiments.
- Week 4(10/23/23 - 10/28/23): Per-Class Accuracy Analysis.
- Week 5(10/29/23 - 11/4/23): Data Distribution Study.
- Week 6(11/5/23 - 11/12/23): Evaluation on Balanced Datasets.
- Week 7(11/13/23 - 11/20/23): Report Writing and Visualization.

**References**
- https://pure-research.york.ac.uk/ws/portalfiles/portal/79047763/2109.04833v2.pdf
- https://github.com/yuchenzhao/iotdi22-mmfl
- http://proceedings.mlr.press/v54/mcmahan17a/mcmahan17a.pdf

